{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT IS ANPR\n",
    "\n",
    "- Objectives:\n",
    "    - Familiarize ourselves with terms Automatic Number Pate Recognition\n",
    "- Steps to build ANPR:\n",
    "    - Acquisition of a photo\n",
    "    - Localization\n",
    "    - Segmentation\n",
    "    - Recognition\n",
    "- Tend to be heavily region specific on a state-by-state level, i.e, each state in US has different and unique license plate design. Thus, there is no one-size-fits-all solution to ANPR.\n",
    "\n",
    "## Step 1: Photo Acquisition\n",
    "- Points to consider:\n",
    "     - Consider our surroundings\n",
    "     - Determine which camera/setup will work best\n",
    "     - Deploy camera in the wild.\n",
    "- Most production-level ANPR systems deployed in the real-world utilize infrared cameras so photos can be captured of vehicles regardless of time of day.\n",
    "- The intermediary step between photo acq. and localization is how to trigger our camaera to capture a photo of a passing vehicle. \\\n",
    "    - Methods include radar and motion detection.\n",
    "\n",
    "## Step 2: Localization\n",
    "- Need to find or localize the region of the image that contains the license plate.\n",
    "- Leverage combination of image processing techniques to reveal regions of an image that could contain a license plate. \n",
    "\n",
    "## Step 3: Segmentation\n",
    "- In order to identify each of the characters on the license plate, we first need to segment them from the license plate background.\n",
    "- Too noisy to apply Optical Character Recognition(OCR) \n",
    "- We perform some sort of adaptive thresholding to cut the characters from the license plate.\n",
    "\n",
    "## Step 4: Recognition\n",
    "- Apply ML to recognize each character that was segmented in the prev. step.\n",
    "- Via feature extraction, such as extracting raw, thresholded pixel intensities, quantifying the contour/outlined region of the character, or extracting more abstract represtations.\n",
    "- In the module, we ue *Black Binary Pixel Sum* descriptor to characterize and quantify characters in the image.\n",
    "- Once we have feature vector associatedd with each character, we then pass it to our ML model to classify the character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
