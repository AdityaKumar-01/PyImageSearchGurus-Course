{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "- Based on concept of linear separability.\n",
    "- A set of data is linearly separable if we can draw a straight line that clearly separates all data points in class #1 from all data points belonging to class #2\n",
    "- The separating line, plane or hyperplane is called the separating hyperplane.\n",
    "- But in case of XOR, the data is not linearly separable. We need a kernel trick.\n",
    "- Margin is the distance between decision boundary and data point closest to it.\n",
    "- In order to find *maximum margin separating hyperplane*, we can frame the problem as an optimization probelm using support vectors, or data points that lie closest to the decision boundary.\n",
    "![Decision boundary and margin](../../images/embedded_images/decision_boundary.jpg)\n",
    "\n",
    "## Kernel Trick\n",
    "- While the points below are not separable in 2D space, we can project them into higher dimension, where they may be linearly separable.\n",
    "![Non-linear separable](../../images/embedded_images/nonlinear_separable.jpg)\n",
    "- In order to do that, compute *Gram matrix/kernel matrix*, which is constructed from the dot product of the original vectors (i.e. the pairwise similarity between all possible pairs of feature vectors), given by:\n",
    "$$\n",
    "G_{i,j} = v_i^Tv_j\n",
    "$$\n",
    "\n",
    "### Types of kernels\n",
    "- Linear\n",
    "$$\n",
    "K(x,y) = x^{T}y\n",
    "$$\n",
    "- Polynomial\n",
    "$$\n",
    "K(x,y) = (x^{T}y + c)^{d}\n",
    "$$\n",
    "- Sigmoid\n",
    "$$\n",
    "K(x,y) = tanh(\\gamma x^{T}y + c)\n",
    "$$\n",
    "- Radial basis funcion(RBF)\n",
    "$$\n",
    "K(x, y) = exp(-\\gamma ||x - y||^{2})\n",
    "$$\n",
    "\n",
    "## Extension to multiple classes\n",
    "- The SVM algorithm was only intended for two classes of data, but we can extend the algorithm to work with > 2 classes by taking the one-against-one approach\n",
    "- Using the one-against-one algorithm, given N classes of data, we train $N \\times (N - 1) / 2$, a classifier for each pair of classes. The exception to this rule is the Linear SVM where a one-vs-the-rest strategy is used where we actually train N separate models.\n",
    "***\n",
    "# Solving the XOR Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import sklearn\n",
    " \n",
    "# handle older versions of sklearn\n",
    "if int((sklearn.__version__).split(\".\")[1]) < 18:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    " \n",
    "# otherwise we're using at lease version 0.18\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    " \n",
    "# generate the XOR data\n",
    "tl = np.random.uniform(size=(100, 2)) + np.array([-2.0, 2.0])\n",
    "tr = np.random.uniform(size=(100, 2)) + np.array([2.0, 2.0])\n",
    "br = np.random.uniform(size=(100, 2)) + np.array([2.0, -2.0])\n",
    "bl = np.random.uniform(size=(100, 2)) + np.array([-2.0, -2.0])\n",
    "X = np.vstack([tl, tr, br, bl])\n",
    "y = np.hstack([[1] * len(tl), [-1] * len(tr), [1] * len(br), [-1] * len(bl)])\n",
    " \n",
    "# construct the training and testing split by taking 75% of the data for training\n",
    "# and 25% for testing\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(X, y, test_size=0.25,\n",
    "                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULTS] SVM w/ Linear Kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      1.00      0.74        44\n",
      "           1       1.00      0.45      0.62        56\n",
      "\n",
      "    accuracy                           0.69       100\n",
      "   macro avg       0.79      0.72      0.68       100\n",
      "weighted avg       0.82      0.69      0.67       100\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the linear SVM model, evaluate it, and show the results\n",
    "print(\"[RESULTS] SVM w/ Linear Kernel\")\n",
    "model = SVC(kernel=\"linear\")\n",
    "model.fit(trainData, trainLabels)\n",
    "print(classification_report(testLabels, model.predict(testData)))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above we obtain only 82% accuracy, since linear method won't work.\n",
    "- Below, we use polynomial kernel, degree=2 and coef=1\n",
    "$$\n",
    "K(x,y) = (x^{T}y + 1)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULTS] SVM w/ Polynomial Kernel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        44\n",
      "           1       1.00      1.00      1.00        56\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the SVM + poly. kernel model, evaluate it, and show the results\n",
    "print(\"[RESULTS] SVM w/ Polynomial Kernel\")\n",
    "model = SVC(kernel=\"poly\", degree=2, coef0=1)\n",
    "model.fit(trainData, trainLabels)\n",
    "print(classification_report(testLabels, model.predict(testData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
