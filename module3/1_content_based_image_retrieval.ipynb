{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based Image Retrieval\n",
    "- Image search engines rely on extracting features from images and then comparing the images for similarity based n the extracted feature vectors and distance metric. CBIR also includes methods to:\n",
    "    - Efficiently store features extracted of image.\n",
    "    - Scale the time it takes to perform a search logarithmically as the size of the image dataset increases linearly.\n",
    "    - Combine techniques from computer vision, information retrieval and databases to build real-worl images search engine that can be deployed online.\n",
    "- Three types of search engines:\n",
    "    - Search by meta-data\n",
    "        - Rarely examine contents of image.\n",
    "        - Rely on textual clues such as manual annotations and tagging performed by humans and automated contextual hints such as text that appears near the image on a webpage.\n",
    "    - Search by example\n",
    "        - Relies on content of image.\n",
    "        - Search engines that quantify contents of an image are called CBIR.\n",
    "    - Search by hybrid approach\n",
    "        - Takes both contextual hints along with search by example strategy\n",
    "\n",
    "## Important terms\n",
    "- **Feature extraction**, which is covered in image descriptors module.\n",
    "- The process of featuree extracion governs the rules, algorithms, and methodologies we use to abstractly quantify the contents of an image using only a list of numbers called a feature vector.\n",
    "- **Index our dataset of features**.\n",
    "- **Distance or similarity function**: Compare pairs of feature vectors for relevance and similarity\n",
    "- **Query image**: The image we submit to CBIR, which takes it, extracts featuers from it and uses our indexed dataset and distance metric to compare images for similarity by utilizing the extracted feature vector.\n",
    "- **Result set** Set of images that are relevant to query, are then sorted and returned to the user\n",
    "\n",
    "## Four Steps of any CBIR system\n",
    "- Defining image descriptor\n",
    "- Feature extractiong and indexing your dataset\n",
    "- Defining your similarity metric\n",
    "- Searching\n",
    "<img src=\"../images/embedded_images/cbir1.jpg\" alt=\"CBIR1\" style=\"width: 500px;\"/>\n",
    "<img src=\"../images/embedded_images/cbir2.jpg\" alt=\"CBIR2\" style=\"width: 500px;\"/>\n",
    "\n",
    "## Evaluating a CBIR system. \n",
    "- Precision: Fraction of retrieved images that are relevant to query\n",
    "$$\n",
    "precision = \\frac{\\#\\:of\\:relevant\\:images\\:retrieved}{total\\:\\#\\:of\\:images\\:retrieved\\:from\\:database}\n",
    "$$\n",
    "- Recall: Fraction of relevant images returned by the query\n",
    "$$\n",
    "recall = \\frac{\\#\\:of\\:relevant\\:images\\:retrieved}{total\\:\\#\\:of\\:relevant\\:images\\:in\\:database}\n",
    "$$\n",
    "- F1-score or f-measure\n",
    "$$\n",
    "f\\mbox{-}score = 2 \\times\\frac{precision \\times recall}{precision + recall}\n",
    "$$\n",
    "- The above metrics useful in academics where it is possible to calc it.\n",
    "- In real-world applications, we instead \n",
    "    - visually investigate the result sets from particular queries  \n",
    "    - utilize our intuition when deciding what it is workin well or not.\n",
    "    - Create small test sets for particular images that we can use the accuracy of our cbir system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
