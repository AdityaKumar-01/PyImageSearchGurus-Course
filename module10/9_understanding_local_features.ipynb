{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Local Features\n",
    "- From 10.2 to 10.8, we considered only image descriptors that quantified an entire image, that is, globally.\n",
    "- Global quantification of an image, meaning every pixel of an image is included in the feature vector computation may not always be appropriate.\n",
    "- Suppose we are trying to identify the covers of books, using only computer vision algorithms. If we use image descriptors(which are global) we end up quantifying regions that don't interest us. \n",
    "- Thus, we use local features where we describe only small local regions of the image that are deemed interesting instead of the entire image.\n",
    "- In local feature descriptors, we generate multiple feature vectors per image.\n",
    "- Usage:\n",
    "    - Align images\n",
    "    - Construct panoramas\n",
    "    - Find objects in images\n",
    "    - Build more robust and powerful ML and content-based image retrieval applications.\n",
    "\n",
    "## Objectives\n",
    "- Obtain high-level understanding of what local features are\n",
    "- Difference between local features and global features such as HOG, LBP,etc.\n",
    "- Keypoint detector and feature vector\n",
    "\n",
    "## Understanding local features\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
