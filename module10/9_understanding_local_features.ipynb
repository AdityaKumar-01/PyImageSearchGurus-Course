{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Local Features\n",
    "- From 10.2 to 10.8, we considered only image descriptors that quantified an entire image, that is, globally.\n",
    "- Global quantification of an image, meaning every pixel of an image is included in the feature vector computation may not always be appropriate.\n",
    "- Suppose we are trying to identify the covers of books, using only computer vision algorithms. If we use image descriptors(which are global) we end up quantifying regions that don't interest us. \n",
    "- Thus, we use local features where we describe only small local regions of the image that are deemed interesting instead of the entire image.\n",
    "- In local feature descriptors, we generate multiple feature vectors per image.\n",
    "- Usage:\n",
    "    - Align images\n",
    "    - Construct panoramas\n",
    "    - Find objects in images\n",
    "    - Build more robust and powerful ML and content-based image retrieval applications.\n",
    "\n",
    "## Objectives\n",
    "- Obtain high-level understanding of what local features are\n",
    "- Difference between local features and global features such as HOG, LBP,etc.\n",
    "- Keypoint detector and feature vector\n",
    "\n",
    "## Understanding local features\n",
    "- \"Feature\" is a region of an image that is both unique and easily recognizable.\n",
    "![Book cover Example](../images/embedded_images/kp_image_patches.jpg)\n",
    "- Patch A: A flat, textureless region. **Flat, low-density regions do not make for good features**\n",
    "- Patch B and C: Edge regions of the book. Edge regions are more interesting and discriminative than flat regions but we can still do better.\n",
    "- Patch D: Corners are considered to be very good interesting and discriminative regions to detect.\n",
    "\n",
    "## Keypoint Detection and Feature extraction\n",
    "- The process of finding and describing interesting regions of an image is broken down into two phases: **key point detection** and **feature extraction**\n",
    "- **KEY POINT EXTRACTION**: Find interesting regions(keypoints) of an image like edges, corners, blobs, or regions of an image where pixel intensities are approximately uniform. Keypoints are simply (x,y) coordinates of interesting salient regions of an image.\n",
    "- **FEATURE EXTRACTION**: For each keypoints, we must describe and quantify the region of the image surrounding the keypoint by extracting a feature vector. We end up extracting multiple feature vectors from an image, one for each keypoint.\n",
    "- We can compare multiple feature vectors either using keypoint matching or bag-ofvisual-words model.\n",
    "\n",
    "## Challenges\n",
    "- Repeatability: Given two images containing same obj., we should detect the same keypoints in both images, despite different viewpoint angles or lighting conditions.\n",
    "- Quality: A high quality keypoint will be both repeatable and contain enough information to be discriminative amongst other regions of image.\n",
    "- Speed: Speed-accuracy trade-off\n",
    "- Invariant: Each feature vectors obtained from regions surrounding each keypoint to be invariant to rotation, scale, lighting changes, contrast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
