{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are image descriptors, feature descriptors and feature vectors\n",
    "\n",
    "- This module: how to quantify and abstractly represent an image using onyl a list of numbers\n",
    "- *Feature extraction*: Process of quantifying an image\n",
    "- Process involves feeding an input image to a descriptor and getting the output (feature vector)\n",
    "- Image descriptors and feature descriptors govern how an image is abstracted, while feature vectors are the output of descriptors.\n",
    "\n",
    "## Feature Vector\n",
    "- Used to represent a variety of properties of an image, such as shape, color or texture of an object in an image.\n",
    "- An abstraction of an image used to characterize and numerically quantify the contents of an image. Basically, it is a list of numbers used to represent an image.\n",
    "- When we input an $NxM$ pixel image to image descriptor, it pops out d-dimensional freature vector. Here, d is the length or number of number of entries inside the list.\n",
    "- Algos used to extract feature vectors are called image descriptors and feature descriptors.\n",
    "\n",
    "## Image Descriptor\n",
    "- Algo and methodology that governs how an input imge is **globally** quantified and returns a feature vector abstractly representing the image content.\n",
    "- The keyword here **global** implies that we are using the whole image in the computation of our feature vector.\n",
    "- Examples: \n",
    "    - Color Channel Statistics (10.2)\n",
    "    - Color Histograms (10.3)\n",
    "    - Local Binary Patterns (10.7)\n",
    "- Once extracted, they can be immediately passed down to the classifier or building image search engine\n",
    "- Simple and intuitive to understand, but can lack the power to distinguish between different objects in images.\n",
    "\n",
    "## Feature Descriptor\n",
    "- Algo and methodology that governs how an input region of an image is locally quantified. A feature descriptor accepts single image and returns multiple feature vectors\n",
    "    - Image Descriptor: 1 image, 1 feature vector out\n",
    "    - Feature Descriptor: 1 image, many feature vectors out.\n",
    "- We provide only certain regions of image to feature descriptor. Example, if we provide $N$ regions from an image to an feature descriptor, we get back $N$ feature vectors.\n",
    "- Examples include *SIFT, SURF, BRISK, BRIEF and FREAK* \n",
    "- Robust to changes in input image, such as rotation, translation and changes in viewpoint.\n",
    "- Not only do we have to store multiple feature vectors per image, which increases our storage overhead, but we need to apply methods such as bag-of-visual-words to take the multiple feature vectors extracted from an image and condense them into a single feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
